{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_path = \"../data/tracking/train\"\n",
    "train_img_dir = \"../data//working/MOT17/train/images\"\n",
    "train_label_dir = \"../data/working/MOT17/train/labels\"\n",
    "\n",
    "# Clear existing directories\n",
    "shutil.rmtree(train_img_dir, ignore_errors=True)\n",
    "shutil.rmtree(train_label_dir, ignore_errors=True)\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "\n",
    "# Copy with PROPER FILENAMES\n",
    "for seq in os.listdir(base_path):\n",
    "    seq_path = os.path.join(base_path, seq)\n",
    "    img_folder = os.path.join(seq_path, \"img1\")\n",
    "    label_folder = os.path.join(seq_path, \"labels\")  # Your converted labels\n",
    "\n",
    "    if os.path.exists(img_folder):\n",
    "        for img_name in os.listdir(img_folder):\n",
    "            if img_name.endswith(\".jpg\"):\n",
    "                # New filename: Sequence + Original name\n",
    "                new_base = f\"{seq}_{os.path.splitext(img_name)[0]}\"\n",
    "\n",
    "                # Copy image\n",
    "                src_img = os.path.join(img_folder, img_name)\n",
    "                dest_img = os.path.join(train_img_dir, f\"{new_base}.jpg\")\n",
    "                shutil.copy2(src_img, dest_img)\n",
    "\n",
    "                # Copy corresponding label\n",
    "                src_label = os.path.join(label_folder, img_name.replace(\".jpg\", \".txt\"))\n",
    "                dest_label = os.path.join(train_label_dir, f\"{new_base}.txt\")\n",
    "\n",
    "                if os.path.exists(src_label):\n",
    "                    shutil.copy2(src_label, dest_label)\n",
    "\n",
    "print(\"✅ Images & labels copied with matching sequence prefixes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_dimensions(seqinfo_path):\n",
    "    \"\"\"Reads seqinfo.ini to extract image width and height.\"\"\"\n",
    "    img_width, img_height = None, None\n",
    "    if os.path.exists(seqinfo_path):\n",
    "        with open(seqinfo_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"imWidth\"):\n",
    "                    img_width = int(line.strip().split(\"=\")[1])\n",
    "                elif line.startswith(\"imHeight\"):\n",
    "                    img_height = int(line.strip().split(\"=\")[1])\n",
    "    return img_width, img_height\n",
    "\n",
    "def convert_mot_to_yolo(mot_base_path, output_base_path):\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "    for sequence in os.listdir(mot_base_path):\n",
    "        seq_path = os.path.join(mot_base_path, sequence)\n",
    "        seqinfo_path = os.path.join(seq_path, \"seqinfo.ini\")\n",
    "        img_width, img_height = get_image_dimensions(seqinfo_path)\n",
    "\n",
    "        # Get image files to match frame IDs\n",
    "        img_folder = os.path.join(seq_path, \"img1\")\n",
    "        img_files = sorted([f for f in os.listdir(img_folder) if f.endswith(\".jpg\")])\n",
    "\n",
    "        # Create empty labels for all frames\n",
    "        for img_file in img_files:\n",
    "            frame_id = int(os.path.splitext(img_file)[0])\n",
    "            label_file = f\"{sequence}_{frame_id:06d}.txt\"  # Match image naming\n",
    "            open(os.path.join(output_base_path, label_file), 'a').close()\n",
    "\n",
    "        # Process MOT annotations\n",
    "        mot_path = os.path.join(seq_path, \"gt\", \"gt.txt\")\n",
    "        if os.path.exists(mot_path):\n",
    "            with open(mot_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                      frame_id, track_id, x, y, w, h, conf, class_id, visibility = map(float, line.strip().split(','))\n",
    "\n",
    "                      # Convert to YOLO format (normalized)\n",
    "                      x_center = (x + w / 2) / img_width\n",
    "                      y_center = (y + h / 2) / img_height\n",
    "                      w = w / img_width\n",
    "                      h = h / img_height\n",
    "\n",
    "                      yolo_line = f\"{int(class_id)} {x_center} {y_center} {w} {h}\\n\"\n",
    "                      frame_txt = f\"{int(frame_id):06d}.txt\"\n",
    "                      frame_id = int(float(line.split(',')[0]))\n",
    "                      label_file = f\"{sequence}_{frame_id:06d}.txt\"\n",
    "                      label_path = os.path.join(output_base_path, label_file)\n",
    "\n",
    "                      # Append to existing label file\n",
    "                      with open(label_path, \"a\") as label_file:\n",
    "                          label_file.write(yolo_line)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing line in {sequence}: {line} -> {e}\")\n",
    "\n",
    "        print(f\"✅ Conversion complete for sequence {sequence}. Labels saved in {output_base_path}\")\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "convert_mot_to_yolo(\n",
    "    mot_base_path=\"../data/tracking/train\",\n",
    "    output_base_path=\"../data/working/MOT17/train/labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "val_img_dir = \"../data/working/MOT17/val/images\"\n",
    "val_label_dir = \"../data/working/MOT17/val/labels\"\n",
    "\n",
    "# Create validation directories\n",
    "os.makedirs(val_img_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "# List all images\n",
    "image_files = sorted(os.listdir(train_img_dir))\n",
    "random.shuffle(image_files)  # Shuffle dataset\n",
    "\n",
    "# Define split ratio (20% validation)\n",
    "val_count = int(len(image_files) * 0.2)\n",
    "\n",
    "# Move images & labels to val/\n",
    "for img_name in image_files[:val_count]:\n",
    "    img_path = os.path.join(train_img_dir, img_name)\n",
    "    label_name = img_name.replace(\".jpg\", \".txt\")\n",
    "    label_path = os.path.join(train_label_dir, label_name)\n",
    "\n",
    "    # Move to validation set\n",
    "    shutil.move(img_path, os.path.join(val_img_dir, img_name))\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.move(label_path, os.path.join(val_label_dir, label_name))\n",
    "\n",
    "print(f\"✅ Moved {val_count} images & labels to validation set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def update_labels(labels_dir):\n",
    "    for file in os.listdir(labels_dir):\n",
    "        file_path = os.path.join(labels_dir, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Change class ID from 1 to 0\n",
    "        updated_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] == \"1\":\n",
    "                parts[0] = \"0\"\n",
    "                updated_lines.append(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "        # Write updated labels\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.writelines(updated_lines)\n",
    "\n",
    "# Update train and val labels\n",
    "update_labels(\"../data/working/MOT17/train/labels\")\n",
    "update_labels(\"../data/working/MOT17/val/labels\")\n",
    "\n",
    "print(\"✅ Updated class indices to 0 in all labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = {\n",
    "    \"train\": \"../data/working/MOT17/train/images\",\n",
    "    \"val\": \"../data/working/MOT17/val/images\",\n",
    "    \"nc\": 1,\n",
    "    \"names\": [\"person\"],  # Define class names\n",
    "    \"train_labels\": \"../data/working/MOT17/train/labels\",  # Add labels path\n",
    "    \"val_labels\": \"../data/working/MOT17/val/labels\"       # Add labels path\n",
    "}\n",
    "\n",
    "yaml_path = \"../data/working/data.yaml\"\n",
    "\n",
    "# Save to YAML file\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training set\n",
    "train_images = set([f.replace(\".jpg\", \"\") for f in os.listdir(\"../data/working/MOT17/train/images\")])\n",
    "train_labels = set([f.replace(\".txt\", \"\") for f in os.listdir(\"../data/working/MOT17/train/labels\")])\n",
    "print(\"Missing training labels:\", len(train_images - train_labels))\n",
    "\n",
    "# Check validation set\n",
    "val_images = set([f.replace(\".jpg\", \"\") for f in os.listdir(\"../data/working/MOT17/val/images\")])\n",
    "val_labels = set([f.replace(\".txt\", \"\") for f in os.listdir(\"../data/working/MOT17/val/labels\")])\n",
    "print(\"Missing validation labels:\", len(val_images - val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Path to COPIED IMAGES (not the original input)\n",
    "train_img_dir = \"../data/working/MOT17/train/images\"\n",
    "\n",
    "# Collect all image paths in working directory\n",
    "image_paths = [\n",
    "    os.path.join(train_img_dir, img)\n",
    "    for img in os.listdir(train_img_dir)\n",
    "    if img.endswith(\".jpg\")\n",
    "]\n",
    "\n",
    "k = 3  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(image_paths)):\n",
    "    # Write train/val .txt files with ABSOLUTE PATHS\n",
    "    with open(f\"../data/working/MOT17/fold_{fold}_train.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([image_paths[i] for i in train_idx]))\n",
    "\n",
    "    with open(f\"../data/working/MOT17/fold_{fold}_val.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([image_paths[i] for i in val_idx]))\n",
    "\n",
    "    # Create YAML\n",
    "    data_yaml = {\n",
    "        \"train\": f\"../data/working/MOT17/fold_{fold}_train.txt\",\n",
    "        \"val\": f\"../data/working/MOT17/fold_{fold}_val.txt\",\n",
    "        \"nc\": 1,\n",
    "        \"names\": [\"person\"]\n",
    "    }\n",
    "    with open(f\"../data/working/data_fold_{fold}.yaml\", \"w\") as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "\n",
    "# Check if files exist\n",
    "for fold in range(k):\n",
    "    train_txt = f\"../data/working/MOT17/fold_{fold}_train.txt\"\n",
    "    val_txt = f\"../data/working/MOT17/fold_{fold}_val.txt\"\n",
    "\n",
    "    if not os.path.exists(train_txt):\n",
    "        print(f\"❌ Missing: {train_txt}\")\n",
    "    if not os.path.exists(val_txt):\n",
    "        print(f\"❌ Missing: {val_txt}\")\n",
    "\n",
    "# Sample first 3 paths from fold 1\n",
    "with open(\"../data/working/MOT17/fold_1_train.txt\", \"r\") as f:\n",
    "    sample_paths = f.readlines()[:3]\n",
    "print(\"Sample paths:\", sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Choose search method (Grid or Random)\n",
    "search_method = \"grid\"  # or \"random\"\n",
    "\n",
    "# Grid Search Parameters\n",
    "grid_params = {\n",
    "    'lr0': [0.01, 0.001],\n",
    "    'momentum': [0.9, 0.95],\n",
    "    'weight_decay': [0.0005, 0.0001]\n",
    "}\n",
    "\n",
    "# Random Search Parameters\n",
    "random_params = {\n",
    "    'lr0': [0.01, 0.005, 0.001],\n",
    "    'momentum': [0.85, 0.9, 0.95],\n",
    "    'weight_decay': [0.0005, 0.0002, 0.0001]\n",
    "}\n",
    "n_iter = 10\n",
    "\n",
    "param_iter = ParameterGrid(grid_params) if search_method == \"grid\" else ParameterSampler(random_params, n_iter)\n",
    "\n",
    "best_map = 0\n",
    "best_params = None\n",
    "\n",
    "for params in param_iter:\n",
    "    print(f\"Training with: {params}\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold in range(k):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load fresh model for each fold\n",
    "    model = YOLO(\"last.pt\")\n",
    "\n",
    "    results = model.train(\n",
    "        data=f\"../data/working/data_fold_{fold}.yaml\",\n",
    "        epochs=1,\n",
    "        batch=1,\n",
    "        imgsz=1080,\n",
    "        workers=4,\n",
    "        device=\"cuda\",\n",
    "        save_period=1,\n",
    "        project=\"kfold_search\",\n",
    "        name=f\"fold_{fold}_lr{params['lr0']}\",\n",
    "        augment=True,\n",
    "        hsv_h=0.015,\n",
    "        hsv_s=0.7,\n",
    "        hsv_v=0.4,\n",
    "        exist_ok=True,\n",
    "        # plots=True,  # Enable detailed plots\n",
    "        **params\n",
    "    )\n",
    "    # results = model.train(resume=True)\n",
    "\n",
    "    fold_metrics.append(results.results_dict['metrics/mAP50-95(B)'])  # Use appropriate metric\n",
    "    print(f\"fold_metrics {fold_metrics}\")\n",
    "\n",
    "    avg_map = sum(fold_metrics) / len(fold_metrics)\n",
    "    if avg_map > best_map:\n",
    "        best_map = avg_map\n",
    "        best_params = params\n",
    "        print(f\"best map & params: {best_map} & {best_params}\")\n",
    "\n",
    "print(f\"Best Params: {best_params} | mAP: {best_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = YOLO(\"../data/working/runs/detect/train/weights/last.pt\")\n",
    "\n",
    "# Training with best params\n",
    "final_model.train(\n",
    "    data=\"../data/working/data.yaml\",\n",
    "    epochs=3,\n",
    "    batch=1,\n",
    "    imgsz=1080,\n",
    "    workers=4,\n",
    "    device=\"cuda\",\n",
    "    save_period=1,\n",
    "    project=\"../data/runs/detect\",\n",
    "    name=\"train\",\n",
    "    **best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "model = YOLO(\"/kaggle/input/last/pytorch/default/1/last.pt\")\n",
    "\n",
    "# Train with aggressive augmentations\n",
    "results = model.train(\n",
    "    data='../data/working/data.yaml',\n",
    "    epochs=4,\n",
    "    imgsz=1088,  # Match original resolution\n",
    "    batch=1,\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    augment=True,\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.75,\n",
    "    mixup=0.5,\n",
    "    degrees=15,\n",
    "    shear=5,\n",
    "    perspective=0.0005,\n",
    "    copy_paste=0.5,\n",
    "    hsv_h=0.3,\n",
    "    hsv_s=0.5,\n",
    "    hsv_v=0.3,\n",
    "    lr0=0.001,\n",
    "    lrf=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    save_period=1,\n",
    "    project=\"../data/working/runs/detect\",\n",
    "    name=\"train\"\n",
    "    # plots=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retail_tracking_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
